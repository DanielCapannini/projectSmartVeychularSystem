{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:27:46.657966Z",
     "start_time": "2024-11-26T13:27:46.639142Z"
    }
   },
   "source": [
    "import time, math, random, cv2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"33264.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Applica una trasformazione di Canny per rilevare i bordi\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Esegui la trasformata di Hough probabilistica per individuare le linee\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "# Disegna le linee rilevate sull'immagine originale\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(gray, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Mostra l'immagine con le linee rilevate\n",
    "cv2.imshow(\"Detected Lines\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:51:36.168338Z",
     "start_time": "2024-11-26T08:51:31.193977Z"
    }
   },
   "source": [
    "# Carica l'immagine\n",
    "image = cv2.imread(\"33264.png\")\n",
    "\n",
    "# Converti l'immagine in scala di grigi\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Calcola una soglia per identificare i pixel più chiari\n",
    "_, thresholded = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Trova i pixel bianchi nell'immagine thresholded\n",
    "white_pixels = np.where(thresholded == 255)\n",
    "\n",
    "# Crea una maschera per estrarre solo i pixel più chiari del 90% per 100%\n",
    "mask = np.zeros_like(gray_image)\n",
    "mask[white_pixels] = gray_image[white_pixels]\n",
    "cv2.imshow(\"Detected Lines\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:52:13.762536Z",
     "start_time": "2024-11-26T08:52:03.763979Z"
    }
   },
   "source": [
    "# Carica l'immagine\n",
    "image = cv2.imread(\"33264.png\")\n",
    "\n",
    "# Converti l'immagine in scala di grigi\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Calcola una soglia per identificare i pixel più chiari\n",
    "thresholded = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Trova i pixel bianchi nell'immagine thresholded\n",
    "white_pixels = np.where(thresholded == 255)\n",
    "\n",
    "# Crea una maschera per estrarre solo i pixel più chiari del 90% per 100%\n",
    "mask = np.zeros_like(gray_image)\n",
    "mask[white_pixels] = gray_image[white_pixels]\n",
    "cv2.imshow(\"Detected Lines\", thresholded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:53:16.239805Z",
     "start_time": "2024-11-26T08:53:11.950123Z"
    }
   },
   "source": [
    "edges = cv2.Canny(mask, 50, 150, apertureSize=3)\n",
    "\n",
    "# Esegui la trasformata di Hough probabilistica per individuare le linee\n",
    "lines = cv2.HoughLinesP(mask, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "# Disegna le linee rilevate sull'immagine originale\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Mostra l'immagine con le linee rilevate\n",
    "cv2.imshow(\"Detected Lines\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:38:30.427020Z",
     "start_time": "2024-11-26T09:37:37.422774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carica l'immagine\n",
    "image = cv2.imread(\"33271.png\")\n",
    "\n",
    "# Converti l'immagine in scala di grigi\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Calcola una soglia per identificare i pixel più chiari\n",
    "_, thresholded = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "thresholded_adaptive = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 25, 2)\n",
    "\n",
    "# Trova i pixel bianchi nell'immagine thresholded\n",
    "white_pixels = np.where(thresholded == 255)\n",
    "\n",
    "# Calcola la soglia personalizzata per estrarre il 95% dei pixel più chiari\n",
    "sorted_pixels = np.sort(gray_image[white_pixels])\n",
    "threshold_value = sorted_pixels[int(0.85 * len(sorted_pixels))]\n",
    "\n",
    "# Applica una sogliatura personalizzata per estrarre il 95% dei pixel più chiari\n",
    "_, custom_thresholded = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Crea una maschera per estrarre solo i pixel più chiari del 95% dell'immagine\n",
    "mask = np.zeros_like(gray_image)\n",
    "mask[custom_thresholded == 255] = gray_image[custom_thresholded == 255]\n",
    "\n",
    "# Definisci il kernel per le operazioni morfologiche\n",
    "kernel = np.ones((3, 3), np.uint8)  # Dimensione del kernel per l'operazione morfologica\n",
    "\n",
    "# Create an image with all values set to 255\n",
    "all_white_image = np.full_like(thresholded_adaptive, 255)\n",
    "\n",
    "# Subtract thresholded_adaptive from the all_white_image\n",
    "result_image = cv2.subtract(all_white_image, thresholded_adaptive)\n",
    "\n",
    "# Esegui l'operazione di chiusura\n",
    "image_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "image_opened = cv2.morphologyEx(image_closed, cv2.MORPH_OPEN, (5,5))\n",
    "image_opened[image_opened > 0] = 255\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"Result Image\", image_opened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:43:41.810689Z",
     "start_time": "2024-11-26T09:43:39.639454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the image\n",
    "image = cv2.imread(\"33264.png\")\n",
    "\n",
    "\n",
    "# Define the coordinates of the top-left and bottom-right corners of the ROI\n",
    "x_start, y_start = 0, 240  # Top-left corner\n",
    "x_end, y_end = 600, 800      # Bottom-right corner\n",
    "\n",
    "# Crop the image using the defined ROI\n",
    "cropped_image = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "# Display the cropped image\n",
    "cv2.imshow(\"Cropped Image\", cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:29:02.745203Z",
     "start_time": "2024-11-26T13:29:00.396656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image = cv2.imread(\"33271.png\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "x_start, y_start = 0, 240  # Top-left corner\n",
    "x_end, y_end = 600, 800      # Bottom-right corner\n",
    "gray_image = gray_image[y_start:y_end, x_start:x_end]\n",
    "_, thresholded = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "white_pixels = np.where(thresholded == 255)\n",
    "sorted_pixels = np.sort(gray_image[white_pixels])\n",
    "threshold_value = sorted_pixels[int(0.85 * len(sorted_pixels))]\n",
    "_, custom_thresholded = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "mask = np.zeros_like(gray_image)\n",
    "mask[custom_thresholded == 255] = gray_image[custom_thresholded == 255]\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "image_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "image_opened = cv2.morphologyEx(image_closed, cv2.MORPH_OPEN, (5,5))\n",
    "image_opened[image_opened > 0] = 255\n",
    "cv2.imshow(\"Result Image\", image_opened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
